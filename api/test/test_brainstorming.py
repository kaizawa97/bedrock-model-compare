#!/usr/bin/env python3
"""
ãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°ã‚¿ã‚¹ã‚¯ã®ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
ã€Œæ„è¦‹ã®å£æ‰“ã¡ã€ã«æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹
"""

import requests
import json
import time

# ãƒ†ã‚¹ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå®Ÿéš›ã®ãƒãƒƒã‚«ã‚½ãƒ³ã®çŠ¶æ³ï¼‰
TEST_PROMPT = """
ç§ã¯ç¤¾å†…ãƒãƒƒã‚«ã‚½ãƒ³ã§ã€Œ50å€‹ã®Bedrockãƒ¢ãƒ‡ãƒ«ã‚’ä¸¦åˆ—å®Ÿè¡Œã—ã¦æ¯”è¼ƒã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€ã‚’ä½œã‚Šã¾ã—ãŸã€‚
ã—ã‹ã—åŒåƒšã‹ã‚‰ã€Œåˆ¥ã«Sonnetã§è‰¯ããªã„ã‹ï¼Ÿã€ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™ã€‚

ä»¥ä¸‹ã®è¨˜äº‹ã®ä¸»å¼µã‚’èª­ã¿ã¾ã—ãŸï¼š
ã€Œãƒ¢ãƒ‡ãƒ«é¸æŠã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ä»»ã›ã‚‹ã®ã¯é–“é•ã„ã€‚ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªå‹•ã§æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶ã¹ãã€‚
Cursorã¯è‡ªå‹•ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚’å®Ÿè£…ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ä½•ã‚‚é¸ã°ãªã„ã€‚ã“ã‚ŒãŒæ­£ã—ã„UIè¨­è¨ˆã ã€‚ã€

è³ªå•ï¼š
1. ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’ã©ã†æ”¹å–„ã™ã¹ãã‹ï¼Ÿ
2. ãƒãƒƒã‚«ã‚½ãƒ³ã§è©•ä¾¡ã•ã‚Œã‚‹ã«ã¯ä½•ã‚’è¦‹ã›ã‚‹ã¹ãã‹ï¼Ÿ
3. å®Ÿç”¨çš„ãªä¾¡å€¤ã‚’ã©ã†ç¤ºã™ã‹ï¼Ÿ

å…·ä½“çš„ã§å®Ÿè£…å¯èƒ½ãªã‚¢ã‚¤ãƒ‡ã‚¢ã‚’3ã¤ã€ãã‚Œãã‚Œç†ç”±ã¨ã¨ã‚‚ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚
"""

# æ¯”è¼ƒã™ã‚‹ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°ã«é©ã—ã¦ã„ãã†ãªãƒ¢ãƒ‡ãƒ«ï¼‰
TEST_MODELS = [
    "us.anthropic.claude-opus-4-5-20251101-v1:0",      # æœ€é«˜æ€§èƒ½
    "us.anthropic.claude-sonnet-4-5-20250929-v1:0",    # ãƒãƒ©ãƒ³ã‚¹
    "us.anthropic.claude-3-5-sonnet-20241022-v2:0",    # å®Ÿç¸¾ã‚ã‚Š
    "us.deepseek.r1-v1:0",                             # æ¨è«–ç‰¹åŒ–
    "amazon.nova-premier-v1:0",                        # Amazonæœ€æ–°
    "amazon.nova-pro-v1:0",                            # ã‚³ã‚¹ãƒ‘
    "us.meta.llama3-3-70b-instruct-v1:0",             # ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹
]

def test_auto_router():
    """Auto Routerã®ãƒ†ã‚¹ãƒˆ"""
    print("=" * 80)
    print("ğŸ¯ Auto Router ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    response = requests.post(
        "http://localhost:8000/api/auto-route",
        json={
            "prompt": TEST_PROMPT,
            "criteria": "balanced"
        }
    )
    
    if response.status_code == 200:
        result = response.json()
        print(f"\nâœ… è‡ªå‹•é¸æŠçµæœ:")
        print(f"   ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {result['task_type']}")
        print(f"   é¸æŠãƒ¢ãƒ‡ãƒ«: {result['selected_model']}")
        print(f"   ç†ç”±: {result['reason']}")
        print(f"   æ¨å®šã‚³ã‚¹ãƒˆ: ${result['estimated_cost']}")
        print(f"   æ¨å®šãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {result['estimated_latency']}ç§’")
        print(f"\n   ä»£æ›¿æ¡ˆ:")
        for alt in result['alternatives']:
            print(f"   - {alt['model_id']}")
            print(f"     ç†ç”±: {alt['reason']}")
            print(f"     ã‚³ã‚¹ãƒˆå€ç‡: {alt['cost_multiplier']}x")
    else:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
        print(response.text)

def test_model_comparison():
    """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã§å®Ÿéš›ã«æ¯”è¼ƒå®Ÿè¡Œ"""
    print("\n" + "=" * 80)
    print("ğŸš€ ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå®Ÿè¡Œ")
    print("=" * 80)
    print(f"\næ¯”è¼ƒã™ã‚‹ãƒ¢ãƒ‡ãƒ«: {len(TEST_MODELS)}å€‹")
    for model in TEST_MODELS:
        print(f"  - {model}")
    
    print(f"\nå®Ÿè¡Œä¸­...")
    start_time = time.time()
    
    response = requests.post(
        "http://localhost:8000/api/execute",
        json={
            "model_ids": TEST_MODELS,
            "prompt": TEST_PROMPT,
            "region": "us-east-1",
            "max_tokens": 2000,
            "temperature": 0.7,
            "max_workers": 10
        }
    )
    
    elapsed = time.time() - start_time
    
    if response.status_code == 200:
        data = response.json()
        results = data['results']
        summary = data['summary']
        
        print(f"\nâœ… å®Ÿè¡Œå®Œäº†ï¼ˆ{elapsed:.1f}ç§’ï¼‰")
        print(f"\nğŸ“Š ã‚µãƒãƒªãƒ¼:")
        print(f"   æˆåŠŸ: {summary['success']}/{summary['total']}")
        print(f"   å¤±æ•—: {summary['failed']}/{summary['total']}")
        print(f"   å¹³å‡æ™‚é–“: {summary['average_time']}ç§’")
        
        # æˆåŠŸã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’åˆ†æ
        successful = [r for r in results if r['success']]
        
        if successful:
            print(f"\nğŸ† æˆåŠŸã—ãŸãƒ¢ãƒ‡ãƒ«ã®åˆ†æ:")
            
            # ã‚³ã‚¹ãƒˆé †ã«ã‚½ãƒ¼ãƒˆ
            by_cost = sorted(successful, key=lambda x: x.get('cost', {}).get('total_cost', 999))
            print(f"\nğŸ’° æœ€å®‰ãƒ¢ãƒ‡ãƒ«:")
            cheapest = by_cost[0]
            print(f"   {cheapest['model_id']}")
            print(f"   ã‚³ã‚¹ãƒˆ: ${cheapest['cost']['total_cost']:.6f}")
            print(f"   æ™‚é–“: {cheapest['elapsed_time']:.2f}ç§’")
            print(f"   å‡ºåŠ›é•·: {len(cheapest['output'])}æ–‡å­—")
            
            # é€Ÿåº¦é †ã«ã‚½ãƒ¼ãƒˆ
            by_speed = sorted(successful, key=lambda x: x['elapsed_time'])
            print(f"\nâš¡ æœ€é€Ÿãƒ¢ãƒ‡ãƒ«:")
            fastest = by_speed[0]
            print(f"   {fastest['model_id']}")
            print(f"   æ™‚é–“: {fastest['elapsed_time']:.2f}ç§’")
            print(f"   ã‚³ã‚¹ãƒˆ: ${fastest['cost']['total_cost']:.6f}")
            print(f"   å‡ºåŠ›é•·: {len(fastest['output'])}æ–‡å­—")
            
            # å‡ºåŠ›ã®è³ªã‚’æ¯”è¼ƒï¼ˆé•·ã•ã§ç°¡æ˜“è©•ä¾¡ï¼‰
            by_length = sorted(successful, key=lambda x: len(x['output']), reverse=True)
            print(f"\nğŸ“ æœ€ã‚‚è©³ç´°ãªå›ç­”:")
            detailed = by_length[0]
            print(f"   {detailed['model_id']}")
            print(f"   å‡ºåŠ›é•·: {len(detailed['output'])}æ–‡å­—")
            print(f"   ã‚³ã‚¹ãƒˆ: ${detailed['cost']['total_cost']:.6f}")
            print(f"   æ™‚é–“: {detailed['elapsed_time']:.2f}ç§’")
            
            # ã‚³ã‚¹ãƒ‘åˆ†æ
            print(f"\nğŸ’ ã‚³ã‚¹ãƒ‘åˆ†æï¼ˆæ–‡å­—æ•°/ã‚³ã‚¹ãƒˆï¼‰:")
            for r in successful:
                cost = r['cost']['total_cost']
                length = len(r['output'])
                if cost > 0:
                    value = length / cost
                    model_name = r['model_id'].split('.')[-1][:30]
                    print(f"   {model_name:30s}: {value:10.0f} æ–‡å­—/$")
            
            # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open('brainstorming_test_results.json', 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ brainstorming_test_results.json ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        else:
            print("\nâŒ ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ãŒå¤±æ•—ã—ã¾ã—ãŸ")
            for r in results:
                print(f"   {r['model_id']}: {r.get('error', 'Unknown error')}")
    
    else:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
        print(response.text)

def test_debate():
    """ãƒ¢ãƒ‡ãƒ«åŒå£«ã®å£æ‰“ã¡ï¼ˆãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆï¼‰ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 80)
    print("ğŸ­ ãƒ¢ãƒ‡ãƒ«å£æ‰“ã¡ï¼ˆãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆï¼‰ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆã«å‚åŠ ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
    debate_models = [
        "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
        "us.deepseek.r1-v1:0",
    ]
    
    topic = "AIã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒ¢ãƒ‡ãƒ«é¸æŠã‚’ä»»ã›ã‚‹ã¹ãã‹ã€ãã‚Œã¨ã‚‚è‡ªå‹•ã§æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶ã¹ãã‹ï¼Ÿ"
    
    print(f"\nğŸ“ ãƒˆãƒ”ãƒƒã‚¯: {topic}")
    print(f"ğŸ“ å‚åŠ ãƒ¢ãƒ‡ãƒ«: {debate_models}")
    print(f"ğŸ“ ãƒ©ã‚¦ãƒ³ãƒ‰æ•°: 2")
    print(f"\nå®Ÿè¡Œä¸­...")
    
    start_time = time.time()
    
    response = requests.post(
        "http://localhost:8000/api/debate",
        json={
            "model_ids": debate_models,
            "topic": topic,
            "rounds": 2,
            "region": "us-east-1",
            "max_tokens": 1500,
            "temperature": 0.7,
            "mode": "debate",
            "enable_reasoning": False
        }
    )
    
    elapsed = time.time() - start_time
    
    if response.status_code == 200:
        data = response.json()
        
        print(f"\nâœ… ãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆå®Œäº†ï¼ˆ{elapsed:.1f}ç§’ï¼‰")
        print(f"\nğŸ“Š ã‚µãƒãƒªãƒ¼:")
        print(f"   ç·ç™ºè¨€æ•°: {data['summary']['total_exchanges']}")
        print(f"   æˆåŠŸ: {data['summary']['success_count']}")
        print(f"   ç·æ™‚é–“: {data['summary']['total_time']:.2f}ç§’")
        
        print(f"\nğŸ¤ è­°è«–ã®å†…å®¹:")
        for round_data in data['rounds']:
            print(f"\n--- ãƒ©ã‚¦ãƒ³ãƒ‰ {round_data['round']} ---")
            for result in round_data['results']:
                if result['success']:
                    model_name = result['model_id'].split('.')[-1][:25]
                    output_preview = result['output'][:200].replace('\n', ' ')
                    print(f"\n[{model_name}]")
                    print(f"  {output_preview}...")
                else:
                    print(f"\n[{result['model_id']}] ã‚¨ãƒ©ãƒ¼: {result.get('error', 'Unknown')}")
        
        # çµæœã‚’ä¿å­˜
        with open('debate_test_results.json', 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ è©³ç´°çµæœã‚’ debate_test_results.json ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    else:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code}")
        print(response.text)

def test_reasoning():
    """æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã®ã‚ªãƒ³ãƒ»ã‚ªãƒ•ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 80)
    print("ğŸ§  æ¨è«–ãƒ¢ãƒ¼ãƒ‰ ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # æ¨è«–å¯¾å¿œãƒ¢ãƒ‡ãƒ«
    reasoning_models = [
        "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
    ]
    
    test_prompt = "1ã‹ã‚‰100ã¾ã§ã®ç´ æ•°ã®åˆè¨ˆã‚’æ±‚ã‚ã¦ãã ã•ã„ã€‚è¨ˆç®—éç¨‹ã‚‚ç¤ºã—ã¦ãã ã•ã„ã€‚"
    
    print(f"\nğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {test_prompt}")
    print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«: {reasoning_models}")
    
    # æ¨è«–OFF
    print(f"\n--- æ¨è«–OFF ---")
    response_off = requests.post(
        "http://localhost:8000/api/execute-with-reasoning",
        json={
            "model_ids": reasoning_models,
            "prompt": test_prompt,
            "region": "us-east-1",
            "max_tokens": 2000,
            "temperature": 0.7,
            "enable_reasoning": False
        }
    )
    
    if response_off.status_code == 200:
        data = response_off.json()
        for r in data['results']:
            if r['success']:
                print(f"  æ™‚é–“: {r['elapsed_time']:.2f}ç§’")
                print(f"  å‡ºåŠ›é•·: {len(r['output'])}æ–‡å­—")
                print(f"  å‡ºåŠ›ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {r['output'][:150]}...")
    
    # æ¨è«–ON
    print(f"\n--- æ¨è«–ON ---")
    response_on = requests.post(
        "http://localhost:8000/api/execute-with-reasoning",
        json={
            "model_ids": reasoning_models,
            "prompt": test_prompt,
            "region": "us-east-1",
            "max_tokens": 2000,
            "temperature": 0.7,
            "enable_reasoning": True,
            "reasoning_budget_tokens": 5000
        }
    )
    
    if response_on.status_code == 200:
        data = response_on.json()
        for r in data['results']:
            if r['success']:
                print(f"  æ™‚é–“: {r['elapsed_time']:.2f}ç§’")
                print(f"  å‡ºåŠ›é•·: {len(r['output'])}æ–‡å­—")
                thinking = r.get('thinking', '')
                if thinking:
                    print(f"  æ¨è«–å†…å®¹é•·: {len(thinking)}æ–‡å­—")
                    print(f"  æ¨è«–ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {thinking[:150]}...")
                print(f"  å‡ºåŠ›ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {r['output'][:150]}...")

def main():
    print("ğŸ§ª Bedrock Auto Router - ãƒ–ãƒ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒŸãƒ³ã‚°ã‚¿ã‚¹ã‚¯ãƒ†ã‚¹ãƒˆ")
    print()
    
    print("ãƒ†ã‚¹ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("  1. Auto Routerãƒ†ã‚¹ãƒˆ")
    print("  2. ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒå®Ÿè¡Œ")
    print("  3. ãƒ¢ãƒ‡ãƒ«å£æ‰“ã¡ï¼ˆãƒ‡ã‚£ãƒ™ãƒ¼ãƒˆï¼‰")
    print("  4. æ¨è«–ãƒ¢ãƒ¼ãƒ‰ ãƒ†ã‚¹ãƒˆ")
    print("  5. ã™ã¹ã¦å®Ÿè¡Œ")
    
    choice = input("\né¸æŠ (1-5): ").strip()
    
    if choice == '1':
        test_auto_router()
    elif choice == '2':
        test_model_comparison()
    elif choice == '3':
        test_debate()
    elif choice == '4':
        test_reasoning()
    elif choice == '5':
        test_auto_router()
        test_model_comparison()
        test_debate()
        test_reasoning()
    else:
        print("ç„¡åŠ¹ãªé¸æŠã§ã™")

if __name__ == "__main__":
    main()
